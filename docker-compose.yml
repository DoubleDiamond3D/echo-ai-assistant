services:
  # Speech Processing Server (uses your existing Ollama)
  speech-server:
    build: ./speech-server
    container_name: echo-speech
    network_mode: host
    volumes:
      - ./models:/app/models
      - ./audio_cache:/app/audio_cache
    environment:
      - OLLAMA_URL=http://localhost:11434
      - STT_MODEL=base
      - DEVICE=cpu
    restart: unless-stopped

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: echo-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

volumes:
  redis_data: